#!/usr/bin/env python3.10
"""Train wake word model using TensorFlow and export directly to TFLite"""
import glob
import os
import sys
import numpy as np

# Force CPU usage (workaround for RTX 5090 GPU compatibility issues)
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

from openwakeword.utils import AudioFeatures
import scipy.io.wavfile as wav
import tensorflow as tf
from tensorflow import keras

def main():
    # Parse command-line arguments
    if len(sys.argv) < 2:
        print("Usage: train_tensorflow.py <wake_word> [output_model_name]")
        print("Example: train_tensorflow.py \"hey zaadoz\"")
        return 1

    wake_word = sys.argv[1]
    output_model = sys.argv[2] if len(sys.argv) > 2 else wake_word.replace(' ', '_').lower()

    # Directories
    generated_dir = "./generated_samples"
    real_dir = "./real_samples"
    negative_dir = "./negative_samples"

    print("=" * 40)
    print("OpenWakeWord Training (TensorFlow)")
    print("=" * 40)
    print(f"Wake word: {wake_word}")
    print(f"Output model: {output_model}")
    print()

    # Collect all positive samples (generated + real)
    positive_paths = sorted(glob.glob(os.path.join(generated_dir, "*.wav")))
    positive_paths += sorted(glob.glob(os.path.join(real_dir, "*.wav")))

    # Collect all negative samples
    negative_paths = sorted(glob.glob(os.path.join(negative_dir, "*.wav")))

    print(f"üìä Training data:")
    print(f"  ‚Ä¢ Positive samples: {len(positive_paths)}")
    print(f"  ‚Ä¢ Negative samples: {len(negative_paths)}")
    print()

    if len(positive_paths) == 0:
        print("‚ùå Error: No positive samples found!")
        print("   Run: ./generate_samples_direct.sh \"" + wake_word + "\" first")
        return 1

    if len(negative_paths) == 0:
        print("‚ö† Warning: No negative samples found. Training without negative samples will be less robust.")
        print("   Consider running: ./generate_samples_direct.sh \"" + wake_word + "\"")

    # Extract features from audio clips using embed_clips (batch processing)
    print("üîä Extracting audio features...")
    F = AudioFeatures()

    # Load all positive audio clips
    print("  ‚Üí Loading positive samples...")
    positive_audio = []
    for i, clip_path in enumerate(positive_paths):
        try:
            sr, audio_data = wav.read(clip_path)

            # Convert stereo to mono if needed
            if len(audio_data.shape) > 1:
                audio_data = audio_data.mean(axis=1).astype(np.int16)

            # AudioFeatures expects int16 data
            if audio_data.dtype != np.int16:
                if audio_data.dtype in [np.float32, np.float64]:
                    audio_data = (audio_data * 32767).astype(np.int16)
                elif audio_data.dtype == np.int32:
                    audio_data = (audio_data / 65536).astype(np.int16)

            positive_audio.append(audio_data)
        except Exception as e:
            print(f"  ‚ö† Skipping {clip_path}: {e}")

    # Load all negative audio clips
    print("  ‚Üí Loading negative samples...")
    negative_audio = []
    for i, clip_path in enumerate(negative_paths):
        try:
            sr, audio_data = wav.read(clip_path)

            # Convert stereo to mono if needed
            if len(audio_data.shape) > 1:
                audio_data = audio_data.mean(axis=1).astype(np.int16)

            # AudioFeatures expects int16 data
            if audio_data.dtype != np.int16:
                if audio_data.dtype in [np.float32, np.float64]:
                    audio_data = (audio_data * 32767).astype(np.int16)
                elif audio_data.dtype == np.int32:
                    audio_data = (audio_data / 65536).astype(np.int16)

            negative_audio.append(audio_data)
        except Exception as e:
            print(f"  ‚ö† Skipping {clip_path}: {e}")

    print(f"  ‚Üí Loaded {len(positive_audio)} positive and {len(negative_audio)} negative clips")

    # Use embed_clips for batch processing (returns shape: N, frames, 96)
    print("  ‚Üí Computing embeddings for positive samples...")
    positive_features = F.embed_clips(positive_audio, batch_size=512, ncpu=4)
    print(f"    Positive features shape: {positive_features.shape}")

    print("  ‚Üí Computing embeddings for negative samples...")
    negative_features = F.embed_clips(negative_audio, batch_size=512, ncpu=4)
    print(f"    Negative features shape: {negative_features.shape}")

    # Stack features and create labels
    X = np.vstack((positive_features, negative_features)).astype(np.float32)
    y = np.array([1]*len(positive_features) + [0]*len(negative_features), dtype=np.float32)

    print(f"üìà Training data shape: {X.shape}")
    print(f"   Positive samples: {np.sum(y == 1):.0f}")
    print(f"   Negative samples: {np.sum(y == 0):.0f}")
    print()

    # Build TensorFlow model - architecture from official openWakeWord notebook
    layer_dim = 32  # Official recommended size for pre-trained embeddings

    # X shape is (N, frames, 96) - need to flatten frames*96
    input_shape = (X.shape[1], X.shape[2])  # (frames, 96)
    flattened_dim = X.shape[1] * X.shape[2]  # frames * 96

    print(f"üìê Model architecture:")
    print(f"   Input shape: {input_shape} ‚Üí flattened to {flattened_dim}")
    print(f"   Hidden layers: {layer_dim} units each")
    print()

    # Calculate class weights (10x weight for negative samples to reduce false positives)
    positive_count = np.sum(y == 1)
    negative_count = np.sum(y == 0)
    total = len(y)
    weight_for_0 = (1 / negative_count) * (total / 2.0)
    weight_for_1 = (1 / positive_count) * (total / 2.0)
    class_weight = {0: weight_for_0 * 10, 1: weight_for_1}  # 10x weight on negatives

    print(f"üìä Class weights:")
    print(f"   Negative class weight: {class_weight[0]:.4f}")
    print(f"   Positive class weight: {class_weight[1]:.4f}")
    print()

    model = keras.Sequential([
        keras.layers.Input(shape=input_shape),
        keras.layers.Flatten(),  # Flatten (frames, 96) to (frames*96,)
        keras.layers.Dense(layer_dim),
        keras.layers.LayerNormalization(),
        keras.layers.ReLU(),
        keras.layers.Dense(layer_dim),
        keras.layers.LayerNormalization(),
        keras.layers.ReLU(),
        keras.layers.Dense(1, activation='sigmoid'),
    ])

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    # Train
    print("üß† Training model...")

    class TrainingCallback(keras.callbacks.Callback):
        def on_epoch_end(self, epoch, logs=None):
            if (epoch + 1) % 2 == 0:
                print(f"  ‚Üí Epoch {epoch+1}/10, Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.2%}")

    history = model.fit(
        X, y,
        epochs=10,  # Official recommended value
        batch_size=512,  # Official recommended value for stability
        class_weight=class_weight,  # 10x weight on negatives to reduce false positives
        verbose=0,
        callbacks=[TrainingCallback()]
    )

    print()

    # Export as SavedModel first
    print("üì¶ Exporting TensorFlow SavedModel...")
    model.export(f"{output_model}_savedmodel")
    print("  ‚úì SavedModel exported")

    # Convert to TFLite
    print()
    print("üì¶ Converting to TFLite...")
    converter = tf.lite.TFLiteConverter.from_saved_model(f"{output_model}_savedmodel")
    # converter.optimizations = [tf.lite.Optimize.DEFAULT]
    tflite_model = converter.convert()

    tflite_path = f"{output_model}.tflite"
    with open(tflite_path, "wb") as f:
        f.write(tflite_model)

    tflite_size = os.path.getsize(tflite_path) / 1024
    print(f"  ‚úì TFLite model saved: {tflite_path}")
    print(f"  ‚Üí TFLite size: {tflite_size:.1f} KB")

    # Cleanup
    import shutil
    shutil.rmtree(f"{output_model}_savedmodel", ignore_errors=True)

    print()
    print("üéâ Training complete!")
    print()
    print("=" * 40)
    print("Training Complete!")
    print("=" * 40)
    print()
    print("Output files:")
    print(f"  - {tflite_path} (TensorFlow Lite - {tflite_size:.1f} KB)")
    print()
    print("For Home Assistant, copy the .tflite file to your config directory:")
    print(f"  custom_components/openwakeword/models/{output_model}.tflite")
    print()

    return 0

if __name__ == "__main__":
    exit(main())
